# THE CUTTING ROOM — WEEKLY TRACKS
## A personal narrative system where your week becomes a story

---

## Concept

The Cutting Room is an interactive storytelling application where users build a weekly chain of posts called a Track.

Instead of a feed, each user creates a sequence of connected moments.  
Each moment is a node.

A node contains:
- one photo OR one text
- an optional caption
- a system-generated 1-sentence recap

The system connects each node to:
1) the user’s previous node
2) visually or semantically similar posts from other users

Over time, a user’s week becomes a structured narrative rather than a timeline.

At the end of the week, the system generates a story describing:
- what their week was about
- how it relates to other people’s experiences

The user is not writing a diary.

The system writes a story about their life patterns.

---

## Core Mechanics

### Daily Posting (Limited)
Users can create up to:
3 nodes per day

Each upload:
- 1 image OR 1 text entry
- optional caption
- optional “why this mattered” short phrase

This constraint forces meaningful posting rather than spamming.

---

### Node Creation

Each new node automatically links to:

1) Previous Node (Personal Continuity)
Creates a personal narrative chain.

2) Similar Community Nodes
Found using embedding similarity across all users.

node -> embedding -> nearest neighbors (kNN)

This allows:
private experience + collective parallel experiences

---

### Auto-Generated Recap

Every node receives a one-sentence recap generated by the system.

The recap is not a caption.

It is a narrative reflection.

Example:

User post:
Photo of empty train platform

System recap:
“You kept moving but avoided arriving.”

---

### Weekly Track

All nodes created in a week form a Track.

Track structure:
Node 1 → Node 2 → Node 3 → ... → Node N

Visible only to:
- the user
- their approved friends (max 40)

---

## Weekly Story Generation

At the end of each week the system generates:

### Personal Story
A 5–8 sentence narrative describing:
- behavioral patterns
- emotional shifts
- recurring imagery

### Social Reflection
The system compares your track to others during the same week and identifies:
- shared moods
- opposite trends
- collective behaviors

---

## Technology Stack

### Frontend (React)
- React (Vite)
- React Router
- TailwindCSS
- Framer Motion (node linking animations)
- Zustand or Redux Toolkit (state management)
- React Query (server state + caching)

Responsibilities:
- Uploading posts
- Viewing node chains
- Interactive timeline visualization
- Reading weekly story
- Friend access controls
- **Deployment**: Hosted on **Aedify.ai** (Vite build)

---

### Backend (Node.js / Express)

REST API server responsible for:
- authentication (Google OAuth 2.0)
- track management
- node linking
- AI job scheduling

Core services:
- Node creation service
- Embedding service bridge
- Neighbor matching service
- Narrative generation triggers
- **Deployment**: Hosted on **Aedify.ai** (Auto-detected Node.js environment)

---

### Database (MongoDB)

MongoDB stores all social and narrative state.

Collections:

Users
_id
username
email
password_hash
friends[]
current_track_id
created_at

Nodes
_id
user_id
content_type
content_url OR text
caption
embedding[]
previous_node_id
neighbor_node_ids[]
recap_sentence
created_at
week_id

Tracks
_id
user_id
week_start
node_ids[]
personal_story
community_story
theme_vector[]
generated_at

---

### Storage
Images stored externally:
- AWS S3 or Cloudflare R2

Database only keeps URL references.

---

## AI + Model Infrastructure

The AI system is NOT inside the React or Express app.  
It is a separate worker service.

Architecture:

React Client
   ↓
Express API (Hosted on Aedify.ai)
   ↓
Model Service (External Team)
   ↓
Database Update

---

### Model Service (External Team)

The Backend (us) communicates with an external Model Service built by the Model Team.

Responsibilities of Model Team:
- Hosted API (Python/FastAPI)
- Embedding generation
- Similarity matching (kNN)
- LLM interaction (Recap & Story generation)

Integration:
- We send HTTP requests to their endpoints.
- They return processed text/vectors.

---

### Embedding Pipeline

For each post:

Text:
embedding(text + caption)

Image:
image → image caption model → caption → embedding

Embedding stored inside the Node document.

Purpose:
- detect similarity
- cluster themes
- power narrative generation

---

### Neighbor Matching

After embedding is created:

1) Compare against recent nodes in the database
2) Compute cosine similarity
3) Select top K neighbors

neighbor_node_ids[] updated in MongoDB.

This creates indirect shared storytelling.

---

### Recap Generator

Worker sends a prompt to an LLM:

Inputs:
- node content
- previous node similarity distance
- neighbor similarity context

Output:
1 reflective sentence

Saved as:
recap_sentence

---

### Weekly Narrative Engine

Runs once per week per user.

Process:

1) Collect all nodes in the track
2) Order chronologically
3) Cluster embeddings
4) Extract recurring motifs
5) Compare to global clusters
6) Generate two outputs:
   - personal story
   - community reflection

Results written into the Track document.

---

## UI Behavior

Personal Page:
- connected node chain
- animated linking lines
- recap sentences appear under nodes

Friend View:
- can read weekly story
- can react/comment

Community:
- similar nodes appear anonymously

Visual direction:
- light theme
- soft colors
- hand-written style elements
- non-corporate aesthetic

---

## Limits (Design Constraints)

3 posts/day max  
40 friends max

These constraints:
- prevent feed addiction
- encourage intentional posting
- create narrative pacing

---

## One Sentence Pitch

The Cutting Room turns a week of small moments into a narrative, connecting your experiences to strangers living parallel lives and revealing the story hidden in everyday behavior.